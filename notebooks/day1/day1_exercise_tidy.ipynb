{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 Exercise: Cleaning Messy Cafe Sales Data\n",
    "\n",
    "**Name:** _Bálint Décsi_  \n",
    "**Date:** October 8, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Transform a messy cafe sales dataset into a tidy format, designate and validate a primary key, and create summary tables.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**File:** `../data/day1/dirty_cafe_sales.csv`  \n",
    "**Rows:** 10,000 cafe transactions  \n",
    "**Data Dictionary:** See `../data/day1/README.md`\n",
    "\n",
    "## Deliverable\n",
    "\n",
    "This notebook should **\"Restart & Run All\"** successfully when you're done!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading\n",
    "\n",
    "### TODO 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.435520Z",
     "iopub.status.busy": "2025-10-07T16:37:04.435255Z",
     "iopub.status.idle": "2025-10-07T16:37:04.440874Z",
     "shell.execute_reply": "2025-10-07T16:37:04.440360Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 1: Import pandas and numpy\n",
    "# Uncomment the lines below and run this cell:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.444179Z",
     "iopub.status.busy": "2025-10-07T16:37:04.443572Z",
     "iopub.status.idle": "2025-10-07T16:37:04.447293Z",
     "shell.execute_reply": "2025-10-07T16:37:04.446499Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 2: Load the data\n",
    "# Uncomment the lines below and run this cell:\n",
    "\n",
    "df = pd.read_csv('../../data/day1/dirty_cafe_sales.csv')\n",
    "# print(f\"✅ Data loaded: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Initial Exploration\n",
    "\n",
    "Before cleaning, let's understand what we have.\n",
    "\n",
    "### TODO 3: Display basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.450201Z",
     "iopub.status.busy": "2025-10-07T16:37:04.449966Z",
     "iopub.status.idle": "2025-10-07T16:37:04.452839Z",
     "shell.execute_reply": "2025-10-07T16:37:04.452159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 10,000 rows × 8 columns\n"
     ]
    }
   ],
   "source": [
    "# TODO 3: Display the shape of the dataframe\n",
    "# Uncomment and run:\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.456531Z",
     "iopub.status.busy": "2025-10-07T16:37:04.456293Z",
     "iopub.status.idle": "2025-10-07T16:37:04.458954Z",
     "shell.execute_reply": "2025-10-07T16:37:04.458390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Transaction ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Item",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Quantity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price Per Unit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total Spent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Payment Method",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Location",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Transaction Date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "00925707-d516-4433-a90e-fed6ff956b9d",
       "rows": [
        [
         "0",
         "TXN_1961373",
         "Coffee",
         "2",
         "2.0",
         "4.0",
         "Credit Card",
         "Takeaway",
         "2023-09-08"
        ],
        [
         "1",
         "TXN_4977031",
         "Cake",
         "4",
         "3.0",
         "12.0",
         "Cash",
         "In-store",
         "2023-05-16"
        ],
        [
         "2",
         "TXN_4271903",
         "Cookie",
         "4",
         "1.0",
         "ERROR",
         "Credit Card",
         "In-store",
         "2023-07-19"
        ],
        [
         "3",
         "TXN_7034554",
         "Salad",
         "2",
         "5.0",
         "10.0",
         "UNKNOWN",
         "UNKNOWN",
         "2023-04-27"
        ],
        [
         "4",
         "TXN_3160411",
         "Coffee",
         "2",
         "2.0",
         "4.0",
         "Digital Wallet",
         "In-store",
         "2023-06-11"
        ],
        [
         "5",
         "TXN_2602893",
         "Smoothie",
         "5",
         "4.0",
         "20.0",
         "Credit Card",
         null,
         "2023-03-31"
        ],
        [
         "6",
         "TXN_4433211",
         "UNKNOWN",
         "3",
         "3.0",
         "9.0",
         "ERROR",
         "Takeaway",
         "2023-10-06"
        ],
        [
         "7",
         "TXN_6699534",
         "Sandwich",
         "4",
         "4.0",
         "16.0",
         "Cash",
         "UNKNOWN",
         "2023-10-28"
        ],
        [
         "8",
         "TXN_4717867",
         null,
         "5",
         "3.0",
         "15.0",
         null,
         "Takeaway",
         "2023-07-28"
        ],
        [
         "9",
         "TXN_2064365",
         "Sandwich",
         "5",
         "4.0",
         "20.0",
         null,
         "In-store",
         "2023-12-31"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_2602893</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN_4433211</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN_6699534</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN_4717867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN_2064365</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID      Item Quantity Price Per Unit Total Spent  \\\n",
       "0    TXN_1961373    Coffee        2            2.0         4.0   \n",
       "1    TXN_4977031      Cake        4            3.0        12.0   \n",
       "2    TXN_4271903    Cookie        4            1.0       ERROR   \n",
       "3    TXN_7034554     Salad        2            5.0        10.0   \n",
       "4    TXN_3160411    Coffee        2            2.0         4.0   \n",
       "5    TXN_2602893  Smoothie        5            4.0        20.0   \n",
       "6    TXN_4433211   UNKNOWN        3            3.0         9.0   \n",
       "7    TXN_6699534  Sandwich        4            4.0        16.0   \n",
       "8    TXN_4717867       NaN        5            3.0        15.0   \n",
       "9    TXN_2064365  Sandwich        5            4.0        20.0   \n",
       "\n",
       "   Payment Method  Location Transaction Date  \n",
       "0     Credit Card  Takeaway       2023-09-08  \n",
       "1            Cash  In-store       2023-05-16  \n",
       "2     Credit Card  In-store       2023-07-19  \n",
       "3         UNKNOWN   UNKNOWN       2023-04-27  \n",
       "4  Digital Wallet  In-store       2023-06-11  \n",
       "5     Credit Card       NaN       2023-03-31  \n",
       "6           ERROR  Takeaway       2023-10-06  \n",
       "7            Cash   UNKNOWN       2023-10-28  \n",
       "8             NaN  Takeaway       2023-07-28  \n",
       "9             NaN  In-store       2023-12-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 3 (continued): Display the first 10 rows\n",
    "# Uncomment and run:\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.461085Z",
     "iopub.status.busy": "2025-10-07T16:37:04.460923Z",
     "iopub.status.idle": "2025-10-07T16:37:04.463027Z",
     "shell.execute_reply": "2025-10-07T16:37:04.462559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Types:\n",
      "Transaction ID      object\n",
      "Item                object\n",
      "Quantity            object\n",
      "Price Per Unit      object\n",
      "Total Spent         object\n",
      "Payment Method      object\n",
      "Location            object\n",
      "Transaction Date    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO 3 (continued): Display column names and types\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"Column Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4: Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.464658Z",
     "iopub.status.busy": "2025-10-07T16:37:04.464511Z",
     "iopub.status.idle": "2025-10-07T16:37:04.466371Z",
     "shell.execute_reply": "2025-10-07T16:37:04.466036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values (NaN) per column:\n",
      "Transaction ID         0\n",
      "Item                 333\n",
      "Quantity             138\n",
      "Price Per Unit       179\n",
      "Total Spent          173\n",
      "Payment Method      2579\n",
      "Location            3265\n",
      "Transaction Date     159\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO 4: Count missing values (NaN) in each column\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"Missing Values (NaN) per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5: Check for sentinel values\n",
    "\n",
    "Look for \"ERROR\" and \"UNKNOWN\" in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.468032Z",
     "iopub.status.busy": "2025-10-07T16:37:04.467921Z",
     "iopub.status.idle": "2025-10-07T16:37:04.469625Z",
     "shell.execute_reply": "2025-10-07T16:37:04.469281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ERROR' values per column:\n",
      "Transaction ID        0\n",
      "Item                292\n",
      "Quantity            170\n",
      "Price Per Unit      190\n",
      "Total Spent         164\n",
      "Payment Method      306\n",
      "Location            358\n",
      "Transaction Date    142\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO 5: Count \"ERROR\" values in each column\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"'ERROR' values per column:\")\n",
    "print((df == 'ERROR').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.471080Z",
     "iopub.status.busy": "2025-10-07T16:37:04.470953Z",
     "iopub.status.idle": "2025-10-07T16:37:04.472678Z",
     "shell.execute_reply": "2025-10-07T16:37:04.472373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'UNKNOWN' values per column:\n",
      "Transaction ID        0\n",
      "Item                344\n",
      "Quantity            171\n",
      "Price Per Unit      164\n",
      "Total Spent         165\n",
      "Payment Method      293\n",
      "Location            338\n",
      "Transaction Date    159\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO 5 (continued): Count \"UNKNOWN\" values in each column\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"'UNKNOWN' values per column:\")\n",
    "print((df == 'UNKNOWN').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: What Issues Did You Find?\n",
    "\n",
    "**TODO:** Write 2-3 sentences describing the data quality issues you observed.\n",
    "\n",
    "_All of the values are stores as strings, which is an undesired state. There is a peak in NaNs for `Payment MEthod` and `Location`. Moreover, both \"ERROR\" and \"UNKNOWN\" are used in all of the columns. These sentinel values should be standardized._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Is This Data Tidy?\n",
    "\n",
    "### TODO 6: Evaluate against tidy data principles\n",
    "\n",
    "**The Three Rules:**\n",
    "1. Each variable is a column\n",
    "2. Each observation is a row\n",
    "3. Each value is a cell\n",
    "\n",
    "**Questions to answer in markdown:**\n",
    "\n",
    "1. What is the unit of observation in this dataset? (What does each row represent?)\n",
    "\n",
    "_Transaction._\n",
    "\n",
    "2. Does each variable have its own column?\n",
    "\n",
    "_Yes._\n",
    "\n",
    "3. Is this dataset tidy? Why or why not?\n",
    "\n",
    "_`Total Spent` is calculated from other two columns, so it might be counted as redundancy. Moreover, it'd be even more granular by making items in transactions the unit of observation._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Identify and Validate Primary Key\n",
    "\n",
    "### TODO 7: Identify the primary key candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.474190Z",
     "iopub.status.busy": "2025-10-07T16:37:04.474081Z",
     "iopub.status.idle": "2025-10-07T16:37:04.475723Z",
     "shell.execute_reply": "2025-10-07T16:37:04.475465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 'Transaction ID' unique? True\n",
      "Total rows: 10,000\n",
      "Unique Transaction IDs: 10,000\n"
     ]
    }
   ],
   "source": [
    "# TODO 7: Check if 'Transaction ID' is unique\n",
    "# Uncomment and run:\n",
    "\n",
    "is_unique = df['Transaction ID'].is_unique\n",
    "print(f\"Is 'Transaction ID' unique? {is_unique}\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Unique Transaction IDs: {df['Transaction ID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.477241Z",
     "iopub.status.busy": "2025-10-07T16:37:04.477138Z",
     "iopub.status.idle": "2025-10-07T16:37:04.478723Z",
     "shell.execute_reply": "2025-10-07T16:37:04.478471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL Transaction IDs: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO 7 (continued): Check for any NULL values in 'Transaction ID'\n",
    "# Uncomment and run:\n",
    "\n",
    "null_count = df['Transaction ID'].isnull().sum()\n",
    "print(f\"NULL Transaction IDs: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.479870Z",
     "iopub.status.busy": "2025-10-07T16:37:04.479799Z",
     "iopub.status.idle": "2025-10-07T16:37:04.481282Z",
     "shell.execute_reply": "2025-10-07T16:37:04.481050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO 7 (continued): If there are duplicates, find them\n",
    "# Uncomment and run:\n",
    "\n",
    "duplicates = df[df.duplicated(subset=['Transaction ID'], keep=False)]\n",
    "print(f\"Duplicate rows: {len(duplicates)}\")\n",
    "if len(duplicates) > 0:\n",
    "    print(\"\\nShowing first few duplicates:\")\n",
    "    display(duplicates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8: Write validation assertions\n",
    "\n",
    "Once you've confirmed (or fixed) the primary key, write assertions to prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.482606Z",
     "iopub.status.busy": "2025-10-07T16:37:04.482536Z",
     "iopub.status.idle": "2025-10-07T16:37:04.483860Z",
     "shell.execute_reply": "2025-10-07T16:37:04.483629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transaction ID is a valid primary key\n"
     ]
    }
   ],
   "source": [
    "# TODO 8: Add assertions to validate primary key\n",
    "# Uncomment and run (these will error if checks fail):\n",
    "\n",
    "assert df['Transaction ID'].is_unique, \"❌ Duplicate transaction IDs found\"\n",
    "assert df['Transaction ID'].notna().all(), \"❌ NULL transaction IDs found\"\n",
    "print(\"✅ Transaction ID is a valid primary key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: Primary Key\n",
    "\n",
    "**TODO:** Explain what you found and any decisions you made.\n",
    "\n",
    "_Transaction ID a good primary key. I haven't found any issues. It is unique and non-NULL._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Handle Missing Values\n",
    "\n",
    "### TODO 9: Standardize missing value representations\n",
    "\n",
    "Convert \"ERROR\", \"UNKNOWN\", and empty strings to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.485071Z",
     "iopub.status.busy": "2025-10-07T16:37:04.485005Z",
     "iopub.status.idle": "2025-10-07T16:37:04.486405Z",
     "shell.execute_reply": "2025-10-07T16:37:04.486172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Replaced 'ERROR', 'UNKNOWN', and empty strings with NaN\n"
     ]
    }
   ],
   "source": [
    "# TODO 9: Replace sentinel values with NaN\n",
    "# Uncomment and run:\n",
    "\n",
    "df = df.replace(['ERROR', 'UNKNOWN', ''], np.nan)\n",
    "print(\"✅ Replaced 'ERROR', 'UNKNOWN', and empty strings with NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.487547Z",
     "iopub.status.busy": "2025-10-07T16:37:04.487451Z",
     "iopub.status.idle": "2025-10-07T16:37:04.488900Z",
     "shell.execute_reply": "2025-10-07T16:37:04.488670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after standardization:\n",
      "Transaction ID         0\n",
      "Item                 969\n",
      "Quantity             479\n",
      "Price Per Unit       533\n",
      "Total Spent          502\n",
      "Payment Method      3178\n",
      "Location            3961\n",
      "Transaction Date     460\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 10,082\n"
     ]
    }
   ],
   "source": [
    "# TODO 9 (continued): Check missing values again after standardization\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"Missing values after standardization:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 10: Decide how to handle missing values\n",
    "\n",
    "**Options:**\n",
    "- Drop rows with missing values in critical columns\n",
    "- Fill with default values\n",
    "- Keep as NaN (document impact on analysis)\n",
    "\n",
    "**Your strategy:**\n",
    "\n",
    "_[Write your strategy here. Example: \"I will keep NULL for `Payment Method` and `Location` because it represents around 30% of rows. ALthough, I decided to exclude NULLs from `Total Spent` as it is a crucial feature.\"]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.490083Z",
     "iopub.status.busy": "2025-10-07T16:37:04.490010Z",
     "iopub.status.idle": "2025-10-07T16:37:04.491558Z",
     "shell.execute_reply": "2025-10-07T16:37:04.491304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Missing value strategy: excluding NULLs from `Total Spent` as it is a crucial feature.\n"
     ]
    }
   ],
   "source": [
    "# TODO 10: Implement your missing value strategy\n",
    "# This is a decision point - choose your approach!\n",
    "# Below is ONE option: Keep NaN as-is (document in reflection above)\n",
    "# Uncomment and run:\n",
    "\n",
    "# For this exercise, we'll keep NaN values and handle them in analysis\n",
    "# (You could also drop rows or fill values - document your choice above!)\n",
    "print(\"✅ Missing value strategy: excluding NULLs from `Total Spent` as it is a crucial feature.\")\n",
    "df = df.dropna(subset=['Total Spent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after standardization:\n",
      "Transaction ID         0\n",
      "Item                 919\n",
      "Quantity             459\n",
      "Price Per Unit       513\n",
      "Total Spent            0\n",
      "Payment Method      3008\n",
      "Location            3757\n",
      "Transaction Date     434\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 9,090\n"
     ]
    }
   ],
   "source": [
    "# Check the result\n",
    "print(\"Missing values after standardization:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Fix Type Issues\n",
    "\n",
    "### TODO 11: Convert Quantity to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.492663Z",
     "iopub.status.busy": "2025-10-07T16:37:04.492601Z",
     "iopub.status.idle": "2025-10-07T16:37:04.493920Z",
     "shell.execute_reply": "2025-10-07T16:37:04.493703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantity converted to Int64 (allows NaN)\n"
     ]
    }
   ],
   "source": [
    "# TODO 11: Convert Quantity to integer\n",
    "# Uncomment and run:\n",
    "\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').astype('Int64')\n",
    "print(\"✅ Quantity converted to Int64 (allows NaN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 12: Convert prices to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.494959Z",
     "iopub.status.busy": "2025-10-07T16:37:04.494897Z",
     "iopub.status.idle": "2025-10-07T16:37:04.496231Z",
     "shell.execute_reply": "2025-10-07T16:37:04.496018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'Price Per Unit' converted to float64\n"
     ]
    }
   ],
   "source": [
    "# TODO 12: Convert 'Price Per Unit' to float\n",
    "# Uncomment and run:\n",
    "\n",
    "df['Price Per Unit'] = pd.to_numeric(df['Price Per Unit'], errors='coerce')\n",
    "print(\"✅ 'Price Per Unit' converted to float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.497301Z",
     "iopub.status.busy": "2025-10-07T16:37:04.497222Z",
     "iopub.status.idle": "2025-10-07T16:37:04.498557Z",
     "shell.execute_reply": "2025-10-07T16:37:04.498360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'Total Spent' converted to float64\n"
     ]
    }
   ],
   "source": [
    "# TODO 12 (continued): Convert 'Total Spent' to float\n",
    "# Uncomment and run:\n",
    "\n",
    "df['Total Spent'] = pd.to_numeric(df['Total Spent'], errors='coerce')\n",
    "print(\"✅ 'Total Spent' converted to float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 13: Convert Transaction Date to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.499594Z",
     "iopub.status.busy": "2025-10-07T16:37:04.499535Z",
     "iopub.status.idle": "2025-10-07T16:37:04.500901Z",
     "shell.execute_reply": "2025-10-07T16:37:04.500651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 'Transaction Date' converted to datetime64\n"
     ]
    }
   ],
   "source": [
    "# TODO 13: Parse Transaction Date as datetime\n",
    "# Uncomment and run:\n",
    "\n",
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n",
    "print(\"✅ 'Transaction Date' converted to datetime64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 14: Verify types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.501979Z",
     "iopub.status.busy": "2025-10-07T16:37:04.501917Z",
     "iopub.status.idle": "2025-10-07T16:37:04.503220Z",
     "shell.execute_reply": "2025-10-07T16:37:04.503004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Column Types:\n",
      "Transaction ID              object\n",
      "Item                        object\n",
      "Quantity                     Int64\n",
      "Price Per Unit             float64\n",
      "Total Spent                float64\n",
      "Payment Method              object\n",
      "Location                    object\n",
      "Transaction Date    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO 14: Display dtypes to verify conversions worked\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"Updated Column Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 15: Write type assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.504248Z",
     "iopub.status.busy": "2025-10-07T16:37:04.504167Z",
     "iopub.status.idle": "2025-10-07T16:37:04.505547Z",
     "shell.execute_reply": "2025-10-07T16:37:04.505348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All types are correct!\n"
     ]
    }
   ],
   "source": [
    "# TODO 15: Add assertions to validate types\n",
    "# Uncomment and run:\n",
    "\n",
    "assert df['Quantity'].dtype in ['int64', 'Int64'], \"❌ Quantity should be integer\"\n",
    "assert df['Price Per Unit'].dtype == 'float64', \"❌ Price should be float\"\n",
    "assert df['Transaction Date'].dtype == 'datetime64[ns]', \"❌ Date should be datetime\"\n",
    "print(\"✅ All types are correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Validate Data Integrity\n",
    "\n",
    "### TODO 16: Check if Total Spent = Quantity × Price Per Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.506508Z",
     "iopub.status.busy": "2025-10-07T16:37:04.506448Z",
     "iopub.status.idle": "2025-10-07T16:37:04.507755Z",
     "shell.execute_reply": "2025-10-07T16:37:04.507531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Calculated expected totals\n"
     ]
    }
   ],
   "source": [
    "# TODO 16: Calculate expected total\n",
    "# Uncomment and run:\n",
    "\n",
    "df['Calculated Total'] = df['Quantity'] * df['Price Per Unit']\n",
    "print(\"✅ Calculated expected totals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.508681Z",
     "iopub.status.busy": "2025-10-07T16:37:04.508625Z",
     "iopub.status.idle": "2025-10-07T16:37:04.509965Z",
     "shell.execute_reply": "2025-10-07T16:37:04.509757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatches found: 0 out of 8544 rows with data\n"
     ]
    }
   ],
   "source": [
    "# TODO 16 (continued): Compare with actual Total Spent\n",
    "# This uses np.isclose() for float comparison (allows tiny rounding differences)\n",
    "# Uncomment and run:\n",
    "\n",
    "mask = df['Total Spent'].notna() & df['Calculated Total'].notna()\n",
    "mismatches = ~np.isclose(\n",
    "    df.loc[mask, 'Total Spent'], \n",
    "    df.loc[mask, 'Calculated Total'],\n",
    "    rtol=1e-05  # Relative tolerance for floating point comparison\n",
    ")\n",
    "print(f\"Mismatches found: {mismatches.sum()} out of {mask.sum()} rows with data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 17: Check for impossible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.511001Z",
     "iopub.status.busy": "2025-10-07T16:37:04.510919Z",
     "iopub.status.idle": "2025-10-07T16:37:04.512263Z",
     "shell.execute_reply": "2025-10-07T16:37:04.512065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with price <= 0: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO 17: Check for negative or zero prices\n",
    "# Uncomment and run:\n",
    "\n",
    "bad_prices = df[df['Price Per Unit'] <= 0]\n",
    "print(f\"Rows with price <= 0: {len(bad_prices)}\")\n",
    "if len(bad_prices) > 0:\n",
    "    display(bad_prices[['Transaction ID', 'Item', 'Price Per Unit']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.513257Z",
     "iopub.status.busy": "2025-10-07T16:37:04.513196Z",
     "iopub.status.idle": "2025-10-07T16:37:04.514548Z",
     "shell.execute_reply": "2025-10-07T16:37:04.514318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with quantity <= 0: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO 17 (continued): Check for zero or negative quantities\n",
    "# Uncomment and run:\n",
    "\n",
    "bad_qty = df[df['Quantity'] <= 0]\n",
    "print(f\"Rows with quantity <= 0: {len(bad_qty)}\")\n",
    "if len(bad_qty) > 0:\n",
    "    display(bad_qty[['Transaction ID', 'Item', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: Data Integrity\n",
    "\n",
    "**TODO:** What did you find? How did you handle integrity issues?\n",
    "\n",
    "_I haven't found any integrity issue._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Create Summary Tables\n",
    "\n",
    "Now that data is clean, answer some business questions!\n",
    "\n",
    "### TODO 18: Total sales by payment method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.515741Z",
     "iopub.status.busy": "2025-10-07T16:37:04.515646Z",
     "iopub.status.idle": "2025-10-07T16:37:04.517504Z",
     "shell.execute_reply": "2025-10-07T16:37:04.517044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales by Payment Method:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Payment Method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total Revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Transaction Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5f11934b-9fde-41c7-936a-7e53cb765a11",
       "rows": [
        [
         "Credit Card",
         "19599.0",
         "2171"
        ],
        [
         "Digital Wallet",
         "19578.0",
         "2187"
        ],
        [
         "Cash",
         "19326.0",
         "2132"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Transaction Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Credit Card</th>\n",
       "      <td>19599.0</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital Wallet</th>\n",
       "      <td>19578.0</td>\n",
       "      <td>2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cash</th>\n",
       "      <td>19326.0</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total Revenue  Transaction Count\n",
       "Payment Method                                  \n",
       "Credit Card           19599.0               2171\n",
       "Digital Wallet        19578.0               2187\n",
       "Cash                  19326.0               2132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO 18: Calculate total revenue and transaction count by payment method\n",
    "# Uncomment and run (this one is fully worked as an example):\n",
    "\n",
    "payment_summary = df.groupby('Payment Method').agg({\n",
    "    'Total Spent': 'sum',\n",
    "    'Transaction ID': 'count'\n",
    "}).round(2)\n",
    "\n",
    "payment_summary.columns = ['Total Revenue', 'Transaction Count']\n",
    "payment_summary = payment_summary.sort_values('Total Revenue', ascending=False)\n",
    "\n",
    "print(\"Sales by Payment Method:\")\n",
    "display(payment_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 19: Most popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.518528Z",
     "iopub.status.busy": "2025-10-07T16:37:04.518469Z",
     "iopub.status.idle": "2025-10-07T16:37:04.519791Z",
     "shell.execute_reply": "2025-10-07T16:37:04.519573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Popular Items (by quantity):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Item",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quantity",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "4c7f96c2-dafd-42cf-a9ae-f1b7a9884de4",
       "rows": [
        [
         "Coffee",
         "3224"
        ],
        [
         "Juice",
         "3196"
        ],
        [
         "Cake",
         "3172"
        ],
        [
         "Salad",
         "3162"
        ],
        [
         "Sandwich",
         "3055"
        ],
        [
         "Smoothie",
         "3024"
        ],
        [
         "Tea",
         "3004"
        ],
        [
         "Cookie",
         "2928"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "Item\n",
       "Coffee      3224\n",
       "Juice       3196\n",
       "Cake        3172\n",
       "Salad       3162\n",
       "Sandwich    3055\n",
       "Smoothie    3024\n",
       "Tea         3004\n",
       "Cookie      2928\n",
       "Name: Quantity, dtype: Int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO 19: Find most popular items by quantity sold\n",
    "# Pattern: df.groupby('Column')['Metric'].sum().sort_values(ascending=False)\n",
    "# Uncomment and adapt:\n",
    "\n",
    "popular_items = df.groupby('Item')['Quantity'].sum().sort_values(ascending=False)\n",
    "print(\"Most Popular Items (by quantity):\")\n",
    "display(popular_items.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.520813Z",
     "iopub.status.busy": "2025-10-07T16:37:04.520733Z",
     "iopub.status.idle": "2025-10-07T16:37:04.522103Z",
     "shell.execute_reply": "2025-10-07T16:37:04.521893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Revenue Items:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Item",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Total Spent",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c760c7e9-26ef-477c-8d4e-8f5609905cdb",
       "rows": [
        [
         "Salad",
         "16605.0"
        ],
        [
         "Sandwich",
         "12956.0"
        ],
        [
         "Smoothie",
         "12556.0"
        ],
        [
         "Juice",
         "9984.0"
        ],
        [
         "Cake",
         "9933.0"
        ],
        [
         "Coffee",
         "6784.0"
        ],
        [
         "Tea",
         "4735.5"
        ],
        [
         "Cookie",
         "3070.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "Item\n",
       "Salad       16605.0\n",
       "Sandwich    12956.0\n",
       "Smoothie    12556.0\n",
       "Juice        9984.0\n",
       "Cake         9933.0\n",
       "Coffee       6784.0\n",
       "Tea          4735.5\n",
       "Cookie       3070.0\n",
       "Name: Total Spent, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO 19 (continued): Find highest revenue items\n",
    "# Use the same pattern but with 'Total Spent' instead of 'Quantity'\n",
    "# Uncomment and adapt:\n",
    "\n",
    "revenue_items = df.groupby('Item')['Total Spent'].sum().sort_values(ascending=False).round(2)\n",
    "print(\"Highest Revenue Items:\")\n",
    "display(revenue_items.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 20: Location comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.523044Z",
     "iopub.status.busy": "2025-10-07T16:37:04.522992Z",
     "iopub.status.idle": "2025-10-07T16:37:04.524334Z",
     "shell.execute_reply": "2025-10-07T16:37:04.524116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales by Location:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "Location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Transaction Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total Revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Avg Transaction Value",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9cb9d881-df7c-426b-8593-cf53dde3c115",
       "rows": [
        [
         "In-store",
         "2869",
         "25906.0",
         "9.03"
        ],
        [
         "Takeaway",
         "2872",
         "25229.5",
         "8.78"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction Count</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Avg Transaction Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>In-store</th>\n",
       "      <td>2869</td>\n",
       "      <td>25906.0</td>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Takeaway</th>\n",
       "      <td>2872</td>\n",
       "      <td>25229.5</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Transaction Count  Total Revenue  Avg Transaction Value\n",
       "Location                                                         \n",
       "In-store               2869        25906.0                   9.03\n",
       "Takeaway               2872        25229.5                   8.78"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO 20: Compare transaction volume and average transaction value by location\n",
    "# This uses .agg() with multiple functions (like TODO 18)\n",
    "# Uncomment and run:\n",
    "\n",
    "location_summary = df.groupby('Location').agg({\n",
    "    'Transaction ID': 'count',\n",
    "    'Total Spent': ['sum', 'mean']\n",
    "}).round(2)\n",
    "\n",
    "location_summary.columns = ['Transaction Count', 'Total Revenue', 'Avg Transaction Value']\n",
    "print(\"Sales by Location:\")\n",
    "display(location_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Final Validation\n",
    "\n",
    "### TODO 21: Run all validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:37:04.525312Z",
     "iopub.status.busy": "2025-10-07T16:37:04.525260Z",
     "iopub.status.idle": "2025-10-07T16:37:04.526675Z",
     "shell.execute_reply": "2025-10-07T16:37:04.526476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final validation...\n",
      "\n",
      "✅ Primary key validated\n",
      "✅ Types validated\n",
      "✅ Data ranges validated\n",
      "\n",
      "✅ All validations passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO 21: Gather all your assertions in one cell to prove data quality\n",
    "# Uncomment and run:\n",
    "\n",
    "print(\"Running final validation...\\n\")\n",
    "\n",
    "# Primary key\n",
    "assert df['Transaction ID'].is_unique, \"❌ Duplicate transaction IDs\"\n",
    "assert df['Transaction ID'].notna().all(), \"❌ NULL transaction IDs\"\n",
    "print(\"✅ Primary key validated\")\n",
    "\n",
    "# Types\n",
    "assert df['Quantity'].dtype in ['int64', 'Int64'], \"❌ Quantity type wrong\"\n",
    "assert df['Price Per Unit'].dtype == 'float64', \"❌ Price type wrong\"\n",
    "assert df['Transaction Date'].dtype == 'datetime64[ns]', \"❌ Date type wrong\"\n",
    "print(\"✅ Types validated\")\n",
    "\n",
    "# Data ranges (only check non-null values)\n",
    "assert (df['Quantity'].dropna() > 0).all(), \"❌ Invalid quantities found\"\n",
    "assert (df['Price Per Unit'].dropna() > 0).all(), \"❌ Invalid prices found\"\n",
    "print(\"✅ Data ranges validated\")\n",
    "\n",
    "print(\"\\n✅ All validations passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 10: Documentation\n",
    "\n",
    "### TODO 22: Document your data cleaning process\n",
    "\n",
    "Write a brief summary (8-10 sentences) of:\n",
    "1. What problems you found\n",
    "2. What decisions you made\n",
    "3. What the implications are for analysis\n",
    "4. What a stakeholder should know about this data\n",
    "\n",
    "---\n",
    "\n",
    "## Data Cleaning Summary\n",
    "\n",
    "_This is a dataset of store transactions with unique IDs for each observation._\n",
    "\n",
    "### Issues Found\n",
    "- _data types: everything is stored in strings_,\n",
    "- _missing data: for `Payment MEthod` and `Location` almost 30%_,\n",
    "- _sentinel values are used, e. g. \"UNKNOWN\".\n",
    "\n",
    "### Actions Taken\n",
    "- _convert columns to integer, float and datetime types_,\n",
    "- _not dropping all the rows in the 30%_,\n",
    "- _standardize with \"NaN\"_.\n",
    "\n",
    "### Assumptions Made\n",
    "- _since both columns mentioned above with high percentage of NULLs have a quite uniform distribution, there might be something behind the missing values_,\n",
    "- _other columns seems like having valid data, which has been checked with type conversion assertions_,\n",
    "- _should ask data collection team if there's difference between \"ERROR\" and \"UNKNOWN\"_. \n",
    "\n",
    "### Implications for Analysis\n",
    "- _be aware that although I haven't dropped missing value rows, I neither imputated them with any value_,\n",
    "- _I strongly suggest finding (a) good candidate value(s) for usage there_.\n",
    "\n",
    "### Data Quality Assessment\n",
    "- _overall, now 100% of data is usable with the constraint of the two columns \"NaN\" value consideration in further analysis_.\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've successfully cleaned a real messy dataset using tidy data principles!\n",
    "\n",
    "**Final check:** Can you **\"Restart & Run All\"** successfully? That's the gold standard!\n",
    "\n",
    "**Reflection:** What was the hardest part? What did you learn?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECBS5294",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
